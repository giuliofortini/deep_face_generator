{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "face_generator.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "X1eJXjC81Voj",
        "m5Nq_6sJ11mp",
        "seD1MXCi2FFR"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_te4vo61RQ8"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHJh32AXxZ-p"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import RMSprop\n",
        "from keras import Model\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.constraints import Constraint\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Input\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import ReLU\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import concatenate\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from PIL import Image, ImageOps\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import numpy as np\n",
        "import os, time, random\n",
        "import pandas as pd\n",
        "\n",
        "print(tf.__version__ )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1eJXjC81Voj"
      },
      "source": [
        "## Dataset download and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wLwnC6Px9aT"
      },
      "source": [
        "import zipfile\n",
        "from urllib import request\n",
        "\n",
        "print(\"Current work directory: {}\".format(os.getcwd()))\n",
        "\n",
        "dataset_folder = os.path.join(os.getcwd(), \"Dataset\")\n",
        "\n",
        "if not os.path.exists(dataset_folder):\n",
        "    os.makedirs(dataset_folder)\n",
        "\n",
        "url =  \"https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip\"\n",
        "\n",
        "dataset_path = os.path.join(dataset_folder, \"celeba.zip\")\n",
        "dir_data = dataset_folder + \"/img_align_celeba\"\n",
        "\n",
        "def download_dataset(download_path, url):\n",
        "  if not os.path.exists(download_path):\n",
        "    print(\"Downloading dataset...\")\n",
        "    request.urlretrieve(url, download_path)\n",
        "    print(\"Download complete!\")\n",
        "  else:\n",
        "    print(\"Downloaded\")\n",
        "\n",
        "\n",
        "def extract_dataset(download_path, extract_path):\n",
        "  if not os.path.exists(extract_path + \"/img_align_celeba\"):\n",
        "    print(\"Extracting dataset... (it may take a while...)\")\n",
        "    with zipfile.ZipFile(download_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(\"Extraction completed!\")\n",
        "  else:\n",
        "    print(\"Extracted\")\n",
        "\n",
        "# Download\n",
        "download_dataset(dataset_path, url)\n",
        "\n",
        "# Extraction\n",
        "extract_dataset(dataset_path, dataset_folder)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5cR4wMeN0QX"
      },
      "source": [
        "preprocessed_path = os.path.join(os.getcwd(), \"Preprocessed\")\n",
        "if not os.path.exists(preprocessed_path):\n",
        "    os.makedirs(preprocessed_path)\n",
        "\n",
        "def crop(path, dest_path):\n",
        "  if not os.path.isdir(dest_path):\n",
        "    os.mkdir(dest_path)\n",
        "  if len(os.listdir(dest_path)) == 0:\n",
        "    images = os.listdir(path)\n",
        "    for img_path in images:\n",
        "      img = Image.open(dir_data + \"/\" + img_path)\n",
        "      f, e = os.path.splitext(img_path)\n",
        "      imCrop = img.crop((25, 45, 128 + 25, 128 + 45)) \n",
        "      imCrop.save(dest_path + \"/\" + f + '.jpg', \"JPEG\", quality=100)\n",
        "\n",
        "\n",
        "cropped_path = preprocessed_path + \"/cropped_celeba\"\n",
        "crop(dir_data, cropped_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exKAdXSeXtWP"
      },
      "source": [
        "def load_attributes(path):\n",
        "  df = pd.read_csv(path)\n",
        "  ids = df['image_id'] \n",
        "  attributes = df.drop(columns=['image_id'])\n",
        "  attributes.replace(to_replace=-1, value=0, inplace=True)\n",
        "  attributes = attributes.apply(lambda x: x.to_numpy(), axis=1)\n",
        "  df = pd.DataFrame(columns = ['file_id', 'attributes'])\n",
        "  df['file_id'] = ids\n",
        "  df['attributes'] = attributes\n",
        "  return df\n",
        "  \n",
        "attributes = load_attributes(os.path.join(\"Dataset\", \"list_attr_celeba.csv\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uGPh3Z4h06u"
      },
      "source": [
        "import random\n",
        "\n",
        "def concat_images(images, size, shape=None):\n",
        "    # Open images and resize them\n",
        "    width, height = size\n",
        "  \n",
        "    # Create canvas for the final image with total size\n",
        "    shape = shape if shape else (1, len(images))\n",
        "    image_size = (width * shape[1], height * shape[0])\n",
        "    image = Image.new('RGB', image_size)\n",
        "    \n",
        "    # Paste images into final image\n",
        "    for row in range(shape[0]):\n",
        "        for col in range(shape[1]):\n",
        "            offset = width * col, height * row\n",
        "            idx = row * shape[1] + col\n",
        "            image.paste(images[idx], offset)\n",
        "    \n",
        "    return image\n",
        "\n",
        "# Get list of image paths\n",
        "image_paths = [os.path.join(cropped_path, f) \n",
        "               for f in os.listdir(cropped_path) if f.endswith('.jpg')]\n",
        "\n",
        "# Random selection of images\n",
        "image_array = random.choices(image_paths, k=84)\n",
        "\n",
        "images = map(Image.open, image_array)\n",
        "images = [ImageOps.fit(image, (64, 64), Image.ANTIALIAS) \n",
        "              for image in images]\n",
        "\n",
        "# Create and save image grid\n",
        "image = concat_images(images, (64, 64), (8, 8))\n",
        "plt.figure(figsize = (16,16))\n",
        "plt.imshow(image)\n",
        "image.save('image.jpg', 'JPEG')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiGwDhz9ye_n"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import load_img\n",
        "\n",
        "def load_dataset(dataset_path, attributes, batch_size, image_shape, subset=False):\n",
        "    dataset_generator = ImageDataGenerator()\n",
        "    if subset:\n",
        "      dataset_generator = dataset_generator.flow_from_dataframe(\n",
        "        dataframe=attributes[0:20000], directory=cropped_path, target_size=(image_shape[0], image_shape[1]),\n",
        "        batch_size=batch_size, x_col='file_id', y_col='attributes', class_mode='raw')\n",
        "    else:\n",
        "      dataset_generator = dataset_generator.flow_from_dataframe(\n",
        "          dataframe=attributes, directory=cropped_path, target_size=(image_shape[0], image_shape[1]),\n",
        "          batch_size=batch_size, x_col='file_id', y_col='attributes', class_mode='raw')\n",
        "\n",
        "    return dataset_generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExINdAzR2Wz_"
      },
      "source": [
        "attributes_list = pd.read_csv(os.path.join('Dataset','list_attr_celeba.csv')).drop(columns=['image_id']).columns\n",
        "attributes_zip = zip(range(0,40), attributes_list)\n",
        "attributes_dict = dict(attributes_zip)\n",
        "print(attributes_dict)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfaGzxOUM7x6"
      },
      "source": [
        "test_attributes = attributes['attributes'][13999]\r\n",
        "print(type(test_attributes))\r\n",
        "test_zip = zip(attributes_list, test_attributes)\r\n",
        "test_dict = dict(test_zip)\r\n",
        "print(test_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKWYOTNi1cJa"
      },
      "source": [
        "## Gan section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5Nq_6sJ11mp"
      },
      "source": [
        "### Function to save generated images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8bIzPn29AGg"
      },
      "source": [
        "generated_images_path = os.path.join(os.getcwd(), \"generated images\")\n",
        "if not os.path.exists(generated_images_path):\n",
        "    os.makedirs(generated_images_path)\n",
        "\n",
        "def save_generated_images(generated_images, epoch, batch_number, batch_size):\n",
        "\n",
        "  plt.figure(figsize=(8, 8), num=2)\n",
        "  gs1 = gridspec.GridSpec(8, 8)\n",
        "  gs1.update(wspace=0, hspace=0)\n",
        "  \n",
        "\n",
        "  for i in range(batch_size):\n",
        "      ax1 = plt.subplot(gs1[i])\n",
        "      ax1.set_aspect('equal')\n",
        "      image = generated_images[i, :, :, :]\n",
        "      image += 1\n",
        "      image *= 127.5\n",
        "      fig = plt.imshow(image.astype(np.uint8))\n",
        "      plt.axis('off')\n",
        "      fig.axes.get_xaxis().set_visible(False)\n",
        "      fig.axes.get_yaxis().set_visible(False)\n",
        "      #image_array.append(Image.fromarray(image.astype('uint8')))\n",
        "\n",
        "  plt.tight_layout()\n",
        "  save_name = 'generated images/epoch_' + str(\n",
        "      epoch + 1) + '_batch_' + str(batch_number + 1) + '.png'\n",
        "\n",
        "  plt.savefig(save_name, bbox_inches='tight', pad_inches=0)\n",
        "  plt.pause(0.0000000001)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcUGzwo31iiR"
      },
      "source": [
        "### Wasserstein loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLAQDfLxSDZV"
      },
      "source": [
        "from keras import backend\r\n",
        "\r\n",
        "def wasserstein_loss(y_true, y_pred):\r\n",
        "\treturn backend.mean(y_true * y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seD1MXCi2FFR"
      },
      "source": [
        "### FID function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv2RimHG_SjK"
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from numpy import cov\n",
        "from numpy import trace\n",
        "from numpy import iscomplexobj\n",
        "from numpy import asarray\n",
        "from numpy.random import shuffle\n",
        "from skimage.transform import resize\n",
        "from scipy.linalg import sqrtm\n",
        "\n",
        "def scale_images(images, new_shape):\n",
        "\timages_list = list()\n",
        "\tfor image in images:\n",
        "\t\t# resize with nearest neighbor interpolation\n",
        "\t\tnew_image = resize(image, new_shape, 0)\n",
        "\t\t# store\n",
        "\t\timages_list.append(new_image)\n",
        "\treturn asarray(images_list)\n",
        "\n",
        "\n",
        "def calculate_fid(model, images1, images2):\n",
        "  # scale images\n",
        "  images1 = scale_images(images1, (299,299,3))\n",
        "  images2 = scale_images(images2, (299,299,3))\n",
        "\n",
        "  images1 = preprocess_input(images1)\n",
        "  images2 = preprocess_input(images2)\n",
        "\t# calculate activations\n",
        "  act1 = model.predict(images1)\n",
        "  act2 = model.predict(images2)\n",
        "  # calculate mean and covariance statistics\n",
        "  mu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
        "  mu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
        "  # calculate sum squared difference between means\n",
        "  ssdiff = np.sum((mu1 - mu2)**2.0)\n",
        "  # calculate sqrt of product between cov\n",
        "  covmean = sqrtm(sigma1.dot(sigma2))\n",
        "  # check and correct imaginary numbers from sqrt\n",
        "  if iscomplexobj(covmean):\n",
        "  \tcovmean = covmean.real\n",
        "  # calculate score\n",
        "  fid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "  return fid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X3LdUd01scN"
      },
      "source": [
        "### Real and Fake data generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoNUjv5z1gjf"
      },
      "source": [
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "  # generate points in the latent space\n",
        "  x_input = np.random.randn(latent_dim * n_samples)\n",
        "  # reshape into a batch of inputs for the network\n",
        "  x_input = x_input.reshape(n_samples, latent_dim)\n",
        "  # generate labels\n",
        "  labels = np.tile(test_attributes, (n_samples, 1))\n",
        "  #return [x_input, labels]\n",
        "  return [x_input, labels]\n",
        "\n",
        "def generate_real_samples(dataset):\n",
        "  X, label = dataset.next()\n",
        "  X /= 127.5\n",
        "  X -= 1\n",
        "  y = np.ones(X.shape[0])\n",
        "  return [X, label.tolist()], y\n",
        "  #return X, y\n",
        "\n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "  # generate points in latent space\n",
        "  x_input, labels = generate_latent_points(latent_dim, n_samples)\n",
        "  #x_input = generate_latent_points(latent_dim, n_samples)\n",
        "  # predict outputs\n",
        "  X = generator.predict([x_input, labels])\n",
        "  #X = generator.predict(x_input)\n",
        "  # create class labels\n",
        "  y = np.zeros((n_samples, 1))\n",
        "  return [X, labels], y\n",
        "  #return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcjKkrM21oKx"
      },
      "source": [
        "### Discriminator, Generator and GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW_hIS3w1Jtk"
      },
      "source": [
        "\n",
        "# define the standalone discriminator model\n",
        "def define_discriminator(in_shape=(64,64,3), label_shape=(40,), n_attributes=40):\n",
        "  input_label = Input(shape=label_shape)\n",
        "  n_nodes = in_shape[0] * in_shape[1] * n_attributes\n",
        "  dense = Dense(2048)(input_label)\n",
        "  #reshape = Reshape((in_shape[0], in_shape[1], n_attributes))(dense)\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "\n",
        "  input_image = Input(shape=in_shape)\n",
        "  #merge = input_image\n",
        "\n",
        "\t# downsample\n",
        "  d = Conv2D(256, (3,3), strides=(2,2), padding='same', input_shape=in_shape, kernel_initializer=init)(input_image)\n",
        "  d = LeakyReLU(alpha=0.2)(d)\n",
        "  d = Dropout(0.2)(d)\n",
        "\t# downsample\n",
        "  d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "  #d = BatchNormalization()(d)\n",
        "  d = LeakyReLU(alpha=0.2)(d)\n",
        "  d = Dropout(0.2)(d)\n",
        "   # downsample\n",
        "  d = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "  #d = BatchNormalization()(d)\n",
        "  d = LeakyReLU(alpha=0.2)(d)\n",
        "  d = Dropout(0.2)(d)\n",
        "  # downsample\n",
        "  d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "  d = LeakyReLU(alpha=0.2)(d)\n",
        "  d = Dropout(0.2)(d)\n",
        "  # downsample\n",
        "  d = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "  d = LeakyReLU(alpha=0.2)(d)\n",
        "  d = Dropout(0.2)(d)\n",
        "  # classifier\n",
        "  d = Flatten()(d)\n",
        "  d = Concatenate()([d, dense])\n",
        "  d = Dropout(0.4)(d)\n",
        "  d = Dense(1, activation='sigmoid')(d)\n",
        "\t# compile model\n",
        "  opt = Adam(lr=0.0001, beta_1=0.2)\n",
        "  model = Model([input_image, input_label], d)\n",
        "  #model = Model(input_image, d)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "  return model\n",
        " \n",
        "# define the standalone generator model\n",
        "def define_generator(latent_dim, n_attributes=40):\n",
        "  input_label = Input(shape=(40,))\n",
        "  n_nodes_label = 8 * 8 * n_attributes\n",
        "  dense = Dense(n_nodes_label)(input_label)\n",
        "  reshape = Reshape((8, 8, n_attributes))(dense)\n",
        "  # foundation for 8x8 image\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "  n_nodes_image = 64 * 8 * 8\n",
        "  image_input = Input(shape=(latent_dim,))\n",
        "  gen = Dense(n_nodes_image, input_dim=latent_dim)(image_input)\n",
        "  gen = Reshape((8, 8, 64))(gen)\n",
        "  merge = Concatenate()([gen, reshape])\n",
        "  # upsample to 16x16\n",
        "  conv = Conv2DTranspose(256, (5,5), strides=(2,2), padding='same', kernel_initializer=init)(merge)\n",
        "  conv = BatchNormalization(momentum=0.8)(conv)\n",
        "  conv = LeakyReLU(alpha=0.1)(conv)\n",
        "  # upsample to 32x32\n",
        "  conv = Conv2DTranspose(128, (5,5), strides=(2,2), padding='same', kernel_initializer=init)(conv)\n",
        "  conv = BatchNormalization(momentum=0.8)(conv)\n",
        "  conv = LeakyReLU(alpha=0.1)(conv)\n",
        "  # upsample to 64x64\n",
        "  conv = (Conv2DTranspose(64, (5,5), strides=(2,2), padding='same', kernel_initializer=init))(conv)\n",
        "  conv = LeakyReLU(alpha=0.1)(conv)\n",
        "  # generate\n",
        "  act = Conv2D(3, (16,16), activation='tanh', padding='same', kernel_initializer=init)(conv)\n",
        "  model = Model([image_input, input_label], act)\n",
        "  #model = Model(image_input, act)\n",
        "  return model\n",
        " \n",
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(generator, discriminator):\n",
        "\t# make weights in the discriminator not trainable\n",
        "  discriminator.trainable = False\n",
        "  gen_image, gen_label = generator.input\n",
        "  #gen_image = generator.input\n",
        "  gen_output = generator.output\n",
        "  gan_output = discriminator([gen_output, gen_label])\n",
        "  #gan_output = discriminator(gen_output)\n",
        "  model = Model([gen_image, gen_label], gan_output)\n",
        "  #model = Model(gen_image, gan_output)\n",
        "\t# compile model\n",
        "  opt = Adam(lr=0.00005, beta_1=0.2)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz561CpyRwcC"
      },
      "source": [
        "d = define_discriminator()\r\n",
        "d.summary()\r\n",
        "plot_model(d)\r\n",
        "g = define_generator(100)\r\n",
        "g.summary()\r\n",
        "plot_model(g, show_shapes=True)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hudjm-fW2KhC"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMsl4IZg2UI1"
      },
      "source": [
        "import time\n",
        "\n",
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, inception_model, dataset, latent_dim, n_epochs=10, n_batch=64):\n",
        "    bat_per_epo = int(202599 / n_batch)\n",
        "    # manually enumerate epochs\n",
        "    for i in range(n_epochs):\n",
        "      start = time.time()\n",
        "      # enumerate batches over the training set\n",
        "      for j in range(bat_per_epo):\n",
        "        # get randomly selected 'real' samples\n",
        "        [X_real, labels_real], y_real = generate_real_samples(dataset)\n",
        "        #X_real, y_real = generate_real_samples(dataset)\n",
        "        current_batch_size = X_real.shape[0]\n",
        "        # update discriminator model weights\n",
        "        labels_real = np.array(labels_real).reshape(current_batch_size,40,1)\n",
        "        d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n",
        "        #d_loss1, _ = d_model.train_on_batch(X_real, y_real)\n",
        "        # generate 'fake' examples\n",
        "        [X_fake, labels_fake], y_fake = generate_fake_samples(\n",
        "            g_model, latent_dim, current_batch_size)\n",
        "        #X_fake, y_fake = generate_fake_samples(\n",
        "         #   g_model, latent_dim, current_batch_size)\n",
        "        labels_fake = np.array(labels_fake).reshape(current_batch_size,40,1)\n",
        "        # update discriminator model weights\n",
        "        d_loss2, _ = d_model.train_on_batch([X_fake, labels_fake], y_fake)\n",
        "        #d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n",
        "        # prepare points in latent space as input for the generator\n",
        "        X_gan = generate_latent_points(latent_dim, current_batch_size)\n",
        "        # create inverted labels for the fake samples\n",
        "        y_gan = np.ones((current_batch_size, 1))\n",
        "        # update the generator via the discriminator's error\n",
        "        g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "        # summarize loss on this batch\n",
        "        if ((j + 1) % 200 == 0):\n",
        "          print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n",
        "              (i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
        "\n",
        "        if ((j + 1) % 100 == 0):\n",
        "            save_generated_images(X_fake, i, j, n_batch)\n",
        "            fid = calculate_fid(inception, X_real, X_fake)\n",
        "            print(\"Fid score: {:.2f}\".format(fid))\n",
        "      \n",
        "      end = time.time()\n",
        "      print(\"Elapsed time: {:.2f} seconds\".format(end-start))\n",
        "    \n",
        "    # save the generator model\n",
        "    g_model.save('generator.h5')\n",
        " \n",
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "# create the discriminator\n",
        "discriminator = define_discriminator()\n",
        "discriminator.summary()\n",
        "plot_model(discriminator, show_shapes=True)\n",
        "# create the generator\n",
        "generator = define_generator(latent_dim)\n",
        "generator.summary()\n",
        "plot_model(generator, show_shapes=True)\n",
        "# create the gan\n",
        "gan_model = define_gan(generator, discriminator)\n",
        "gan_model.summary()\n",
        "plot_model(gan_model, show_shapes=True)\n",
        "# load image data\n",
        "dataset = load_dataset(cropped_path, attributes, 64, (64,64,3))\n",
        "# prepare the inception model\n",
        "inception = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n",
        "# train model\n",
        "train(generator, discriminator, gan_model, inception, dataset, latent_dim, n_epochs=15, n_batch=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUHYb13iU4-w"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "generator = load_model('generator.h5')\n",
        "real, _ = generate_real_samples(dataset)\n",
        "fake, _ = generate_fake_samples(generator, latent_dim, 64)\n",
        "real_resized = scale_images(real, (299,299,3))\n",
        "fake_resized = scale_images(fake, (299,299,3))\n",
        "fid = calculate_fid(inception, real_resized, fake_resized)\n",
        "print(\"Fid score: {:.2f}\".format(fid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycNjNwFz8l91"
      },
      "source": [
        " !zip -r /content/generated_images.zip /content/generated\\ images\n",
        " \n",
        "from google.colab import files\n",
        "files.download(\"/content/generated_images.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZewJH0_Zgt53"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}