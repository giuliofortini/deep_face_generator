{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "face_generator.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "X1eJXjC81Voj",
        "m5Nq_6sJ11mp",
        "seD1MXCi2FFR"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_te4vo61RQ8"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHJh32AXxZ-p"
      },
      "source": [
        "from keras import Model\n",
        "from keras import backend\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.constraints import Constraint\n",
        "from keras.layers import Dense, Input, Conv2D, Concatenate, Flatten, BatchNormalization, Embedding, Activation, Dropout, LeakyReLU, ReLU, Reshape, Conv2DTranspose, concatenate, MaxPooling2D\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import numpy as np\n",
        "import os, time, random, zipfile, cv2\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import files\n",
        "from urllib import request\n",
        "from google.colab import drive\n",
        "from scipy.linalg import sqrtm\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDRcDYmHe1OZ"
      },
      "source": [
        "### Paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjhgzyTse0iA"
      },
      "source": [
        "dataset_folder = os.path.join(os.getcwd(), \"Dataset\")\r\n",
        "dataset_path = os.path.join(dataset_folder, \"celeba.zip\")\r\n",
        "extract_path = os.path.join(dataset_folder, \"img_align_celeba\")\r\n",
        "cropped_path = os.path.join(dataset_folder, \"Cropped\")\r\n",
        "attributes_path = os.path.join(dataset_folder, \"list_attr_celeba.csv\")\r\n",
        "generated_images_path = os.path.join(os.getcwd(), \"Generated images\")\r\n",
        "generator_path = os.path.join(os.getcwd(), \"Generators\")\r\n",
        "discriminator_path = os.path.join(os.getcwd(), \"Discriminators\")\r\n",
        "g_model_path = os.path.join(generator_path, \"generator.h5\")\r\n",
        "g_model_path_drive = os.path.join(\"/content/drive/MyDrive/Generators\", \"generator.h5\")\r\n",
        "d_model_path = os.path.join(discriminator_path, \"discriminator.h5\")\r\n",
        "d_model_path_drive = os.path.join(\"/content/drive/MyDrive/Discriminators\", \"discriminator.h5\")\r\n",
        "\r\n",
        "if not os.path.exists(generator_path):\r\n",
        "  os.makedirs(generator_path)\r\n",
        "\r\n",
        "if not os.path.exists(discriminator_path):\r\n",
        "  os.makedirs(discriminator_path)\r\n",
        "\r\n",
        "if not os.path.exists(dataset_folder):\r\n",
        "    os.makedirs(dataset_folder)\r\n",
        "\r\n",
        "if not os.path.exists(cropped_path):\r\n",
        "    os.makedirs(cropped_path)\r\n",
        "\r\n",
        "if not os.path.exists(generated_images_path):\r\n",
        "    os.makedirs(generated_images_path)\r\n",
        "\r\n",
        "dataset_url =  \"https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1eJXjC81Voj"
      },
      "source": [
        "## Dataset download and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wLwnC6Px9aT"
      },
      "source": [
        "def download_dataset(download_path, url):\n",
        "  if not os.path.exists(download_path):\n",
        "    print(\"Downloading dataset...\", end=\" \")\n",
        "    request.urlretrieve(url, download_path)\n",
        "    print(\"Done!\")\n",
        "  else:\n",
        "    print(\"Already downloaded\")\n",
        "\n",
        "def extract_dataset(download_path, dataset_folder, extract_path):\n",
        "  if not os.path.exists(extract_path):\n",
        "    print(\"Extracting dataset...\", end=\" \")\n",
        "    with zipfile.ZipFile(download_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(dataset_folder)\n",
        "    print(\"Done!\")\n",
        "  else:\n",
        "    print(\"Already extracted\")\n",
        "\n",
        "# Download\n",
        "download_dataset(dataset_path, dataset_url)\n",
        "\n",
        "# Extraction\n",
        "extract_dataset(dataset_path, dataset_folder, extract_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5cR4wMeN0QX"
      },
      "source": [
        "def crop(source_path, dest_path):\n",
        "  if not os.path.isdir(dest_path):\n",
        "    os.mkdir(dest_path)\n",
        "  if len(os.listdir(dest_path)) == 0:\n",
        "    images = os.listdir(source_path)\n",
        "    for img_path in images:\n",
        "      img = Image.open(source_path + \"/\" + img_path)\n",
        "      f, e = os.path.splitext(img_path)\n",
        "      imCrop = img.crop((25, 45, 128 + 25, 128 + 45)) \n",
        "      imCrop.save(dest_path + \"/\" + f + '.jpg', \"JPEG\", quality=100)\n",
        "\n",
        "crop(extract_path, cropped_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eGb1I6VIIk5"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5w1in7AISM5"
      },
      "source": [
        "!cp '/content/drive/MyDrive/list_attr_celeba.csv' '/content/Dataset'\r\n",
        "!cp '/content/drive/MyDrive/Generators/generator.h5' '/content/Generators/generator.h5'\r\n",
        "!cp '/content/drive/MyDrive/Discriminators/discriminator.h5' '/content/Discriminators/discriminator.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exKAdXSeXtWP"
      },
      "source": [
        "def load_attributes(path):\n",
        "  df = pd.read_csv(path)\n",
        "  ids = df['image_id'] \n",
        "  attributes = df.drop(columns=['image_id', '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes', \n",
        "                                'Bangs', 'Big_Lips', 'Big_Nose', 'Blurry', 'Bushy_Eyebrows', 'Double_Chin', \n",
        "                                'Goatee', 'Mouth_Slightly_Open',  'Narrow_Eyes', 'Oval_Face', 'Pointy_Nose', \n",
        "                                'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns', 'Straight_Hair', 'Wavy_Hair',\n",
        "                                'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie'])\n",
        "  attributes.replace(to_replace=-1, value=0, inplace=True)\n",
        "  attributes = attributes.apply(lambda x: x.to_numpy(), axis=1)\n",
        "  df = pd.DataFrame(columns = ['file_id', 'attributes'])\n",
        "  df['file_id'] = ids\n",
        "  df['attributes'] = attributes\n",
        "  return df\n",
        "  \n",
        "attributes = load_attributes(attributes_path)\n",
        "print(attributes)\n",
        "attributes_list = pd.read_csv(attributes_path).drop(columns=['image_id', '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes', \n",
        "                                'Bangs', 'Big_Lips', 'Big_Nose', 'Blurry', 'Bushy_Eyebrows', 'Double_Chin', \n",
        "                                'Goatee', 'Mouth_Slightly_Open',  'Narrow_Eyes', 'Oval_Face', 'Pointy_Nose', \n",
        "                                'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns', 'Straight_Hair', 'Wavy_Hair',\n",
        "                                'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie']).columns\n",
        "attributes_dict = dict(enumerate(attributes_list))\n",
        "print(attributes_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4d1Y2HoXvbs"
      },
      "source": [
        "def create_custom_label(attr):\r\n",
        "  label = []\r\n",
        "  for k,v in attributes_dict.items():\r\n",
        "    if v in attr:\r\n",
        "      label.append(1)\r\n",
        "    else:\r\n",
        "      label.append(0)\r\n",
        "  return np.array(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwU9PDQSLXJy"
      },
      "source": [
        "def decode_label(label):\r\n",
        "  attr = []\r\n",
        "  for i,element in enumerate(label):\r\n",
        "    if element == 1:\r\n",
        "      attr.append(attributes_dict[i])\r\n",
        "  return attr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uGPh3Z4h06u"
      },
      "source": [
        "def concat_images(images, size, shape=None):\n",
        "    # Open images and resize them\n",
        "    width, height = size\n",
        "  \n",
        "    # Create canvas for the final image with total size\n",
        "    shape = shape if shape else (1, len(images))\n",
        "    image_size = (width * shape[1], height * shape[0])\n",
        "    image = Image.new('RGB', image_size)\n",
        "    \n",
        "    # Paste images into final image\n",
        "    for row in range(shape[0]):\n",
        "        for col in range(shape[1]):\n",
        "            offset = width * col, height * row\n",
        "            idx = row * shape[1] + col\n",
        "            image.paste(images[idx], offset)\n",
        "    \n",
        "    return image\n",
        "\n",
        "# Get list of image paths\n",
        "image_paths = [os.path.join(cropped_path, f) \n",
        "               for f in os.listdir(cropped_path) if f.endswith('.jpg')]\n",
        "\n",
        "# Random selection of images\n",
        "image_array = random.choices(image_paths, k=84)\n",
        "\n",
        "images = map(Image.open, image_array)\n",
        "images = [ImageOps.fit(image, (64, 64), Image.ANTIALIAS) \n",
        "              for image in images]\n",
        "\n",
        "# Create and save image grid\n",
        "image = concat_images(images, (64, 64), (8, 8))\n",
        "plt.figure(figsize = (16,16))\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiGwDhz9ye_n"
      },
      "source": [
        "def load_dataset(cropped_path, attributes, batch_size, image_shape, subset=False):\n",
        "    dataset_generator = ImageDataGenerator()\n",
        "    if subset:\n",
        "      dataset_generator = dataset_generator.flow_from_dataframe(\n",
        "        dataframe=attributes[0:20000], directory=cropped_path, target_size=(image_shape[0], image_shape[1]),\n",
        "        batch_size=batch_size, x_col='file_id', y_col='attributes', class_mode='raw')\n",
        "    else:\n",
        "      dataset_generator = dataset_generator.flow_from_dataframe(\n",
        "        dataframe=attributes, directory=cropped_path, target_size=(image_shape[0], image_shape[1]),\n",
        "        batch_size=batch_size, x_col='file_id', y_col='attributes', class_mode='raw')\n",
        "\n",
        "    return dataset_generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKWYOTNi1cJa"
      },
      "source": [
        "## Gan section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5Nq_6sJ11mp"
      },
      "source": [
        "### Function to save generated images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8bIzPn29AGg"
      },
      "source": [
        "def save_generated_images(generated_images, epoch, batch_number, batch_size):\n",
        "\n",
        "  plt.figure(figsize=(8, 8), num=2)\n",
        "  gs1 = gridspec.GridSpec(8, 8)\n",
        "  gs1.update(wspace=0, hspace=0)\n",
        "\n",
        "  for i in range(batch_size):\n",
        "      ax1 = plt.subplot(gs1[i])\n",
        "      ax1.set_aspect('equal')\n",
        "      image = generated_images[i, :, :, :]\n",
        "      image += 1\n",
        "      image *= 127.5\n",
        "      fig = plt.imshow(image.astype(np.uint8))\n",
        "      plt.axis('off')\n",
        "      fig.axes.get_xaxis().set_visible(False)\n",
        "      fig.axes.get_yaxis().set_visible(False)\n",
        "      \n",
        "  plt.tight_layout()\n",
        "  save_name = 'Generated images/epoch_' + str(\n",
        "      epoch + 1) + '_batch_' + str(batch_number + 1) + '.png'\n",
        "\n",
        "  plt.savefig(save_name, bbox_inches='tight', pad_inches=0)\n",
        "  plt.pause(0.0000000001)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcUGzwo31iiR"
      },
      "source": [
        "### Wasserstein loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLAQDfLxSDZV"
      },
      "source": [
        "def wasserstein_loss(y_true, y_pred):\r\n",
        "\treturn backend.mean(y_true * y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seD1MXCi2FFR"
      },
      "source": [
        "### FID function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv2RimHG_SjK"
      },
      "source": [
        "def scale_images(images, new_shape):\n",
        "  images_list = list()\n",
        "\n",
        "  for image in images:\n",
        "    # resize with bilinear interpolation\n",
        "\t  new_image = cv2.resize(image, (new_shape, new_shape))\n",
        "    # store\n",
        "\t  images_list.append(new_image)\n",
        "  return np.asarray(images_list)\n",
        "\n",
        "def calculate_fid(model, images1, images2):\n",
        "  # scale images\n",
        "  images1 = scale_images(images1, 299)\n",
        "  images2 = scale_images(images2, 299)\n",
        "\n",
        "  images1 = preprocess_input(images1)\n",
        "  images2 = preprocess_input(images2)\n",
        "\n",
        "  # calculate activations\n",
        "  act1 = model.predict(images1)\n",
        "  act2 = model.predict(images2)\n",
        "\n",
        "  # calculate mean and covariance statistics\n",
        "  mu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)\n",
        "  mu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)\n",
        "\n",
        "  # calculate sum squared difference between means\n",
        "  ssdiff = np.sum((mu1 - mu2)**2.0)\n",
        "\n",
        "  # calculate sqrt of product between cov\n",
        "  covmean = sqrtm(sigma1.dot(sigma2))\n",
        "\n",
        "  # check and correct imaginary numbers from sqrt\n",
        "  if np.iscomplexobj(covmean):\n",
        "    covmean = covmean.real\n",
        "\n",
        "  # calculate score\n",
        "  fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "  return fid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X3LdUd01scN"
      },
      "source": [
        "### Real and Fake data generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoNUjv5z1gjf"
      },
      "source": [
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "  # generate points in the latent space\n",
        "  x_input = np.random.randn(latent_dim * n_samples)\n",
        "  \n",
        "  # reshape into a batch of inputs for the network\n",
        "  x_input = x_input.reshape(n_samples, latent_dim)\n",
        "  \n",
        "  # generate labels\n",
        "  labels = np.array(random.sample(list(attributes['attributes']), n_samples))\n",
        "  \n",
        "  return [x_input, labels]\n",
        "\n",
        "def generate_real_samples(dataset):\n",
        "  X, label = dataset.next()\n",
        "  X /= 127.5\n",
        "  X -= 1\n",
        "  y = -np.ones(X.shape[0])\n",
        "  return [X, label.tolist()], y\n",
        "\n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(generator, latent_dim, n_samples, custom_label=None):\n",
        "  \n",
        "  # generate points in latent space\n",
        "  x_input, labels = generate_latent_points(latent_dim, n_samples)\n",
        "  \n",
        "  # predict outputs\n",
        "  if custom_label is not None:\n",
        "    labels = np.tile(custom_label, (n_samples,1))\n",
        "  \n",
        "  X = generator.predict([x_input, labels])\n",
        "  \n",
        "  # create class labels\n",
        "  y = np.ones((n_samples, 1))\n",
        "  \n",
        "  return [X, labels], y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcjKkrM21oKx"
      },
      "source": [
        "### Discriminator, Generator and GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW_hIS3w1Jtk",
        "cellView": "code"
      },
      "source": [
        "# define the standalone discriminator model\n",
        "class ClipConstraint(Constraint):\n",
        "  # set clip value when initialized\n",
        "  def __init__(self, clip_value):\n",
        "    self.clip_value = clip_value\n",
        "\n",
        "  # clip model weights to hypercube\n",
        "  def __call__(self, weights):\n",
        "    return backend.clip(weights, -self.clip_value, self.clip_value)\n",
        "\n",
        "  # get the config\n",
        "  def get_config(self):\n",
        "    return {'clip_value': self.clip_value}\n",
        "\n",
        "\n",
        "const = ClipConstraint(0.01)\n",
        "\n",
        "def define_discriminator(in_shape=(64,64,3), label_shape=(15,), n_attributes=15):\n",
        "\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "\n",
        "  input_image = Input(shape=in_shape)\n",
        "\n",
        "  # define the constraint\n",
        "  const = ClipConstraint(0.01)\n",
        "\n",
        "\t# downsample\n",
        "  d = Conv2D(32, (5,5), strides=(2,2), padding='same', input_shape=in_shape, kernel_initializer=init, kernel_constraint=const)(input_image)\n",
        "  d = LeakyReLU(alpha=0.2)(d)\n",
        "  d = Dropout(0.2)(d)\n",
        "\t\n",
        "  # downsample\n",
        "  d = Conv2D(64, (5,5), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
        "  d = LeakyReLU(alpha=0.2)(d)\n",
        "  d = Dropout(0.2)(d)\n",
        "  \n",
        "  # downsample\n",
        "  d = Conv2D(128, (5,5), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
        "  d = LeakyReLU(alpha=0.2)(d)\n",
        "  d = Dropout(0.2)(d)\n",
        "  \n",
        "  # downsample\n",
        "  d = Conv2D(256, (5,5), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
        "  d = LeakyReLU(alpha=0.2)(d)\n",
        "  d = Dropout(0.2)(d)\n",
        "  \n",
        "  # downsample\n",
        "  #d = Conv2D(256, (3,3), strides=(1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
        "  #d = LeakyReLU(alpha=0.2)(d)\n",
        "  #d = Dropout(0.2)(d)si\n",
        "  \n",
        "  \n",
        "  # classifier\n",
        "  d = Flatten()(d)\n",
        "  #d = Concatenate()([d, input_label])\n",
        "  d = Dropout(0.4)(d)\n",
        "  out1 = Dense(1, activation='linear')(d)\n",
        "  out2 = Dense(n_attributes, activation='sigmoid')(d)\n",
        "\t\n",
        "  # compile model\n",
        "  opt = RMSprop(lr=0.00005)\n",
        "\n",
        "  model = Model(input_image,  [out1, out2])\n",
        "  \n",
        "  model.compile(loss=[wasserstein_loss, 'binary_crossentropy'], optimizer=opt, metrics=['accuracy'])\n",
        "  return model\n",
        " \n",
        "# define the standalone generator model\n",
        "def define_generator(latent_dim, n_attributes=15):\n",
        "  input_label = Input(shape=(15,))\n",
        "\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "  \n",
        "  image_input = Input(shape=(latent_dim,))\n",
        "  \n",
        "  merged_input = Concatenate()([image_input, input_label])  \n",
        "  \n",
        "  hid = Dense(115 * 8 * 8, activation='relu')(merged_input)    \n",
        "  hid = BatchNormalization(momentum=0.8)(hid)\n",
        "  hid = LeakyReLU(alpha=0.2)(hid)\n",
        "  hid = Reshape((8, 8, 115))(hid)\n",
        "  \n",
        "  # upsample to 16x16\n",
        "  conv = Conv2DTranspose(64, (5,5), strides=(2,2), padding='same', kernel_initializer=init)(hid)\n",
        "  conv = BatchNormalization(momentum=0.8)(conv)\n",
        "  conv = LeakyReLU(alpha=0.2)(conv)\n",
        "  \n",
        "  # upsample to 32x32\n",
        "  conv = Conv2DTranspose(128, (5,5), strides=(2,2), padding='same', kernel_initializer=init)(conv)\n",
        "  conv = BatchNormalization(momentum=0.8)(conv)\n",
        "  conv = LeakyReLU(alpha=0.2)(conv)\n",
        "  \n",
        "  # upsample to 64x64\n",
        "  conv = Conv2DTranspose(256, (5,5), strides=(2,2), padding='same', kernel_initializer=init)(conv)\n",
        "  conv = LeakyReLU(alpha=0.2)(conv)\n",
        "  \n",
        "  # generate\n",
        "  act = Conv2D(3, (16,16), activation='tanh', padding='same', kernel_initializer=init)(conv)\n",
        "  \n",
        "  model = Model([image_input, input_label], act)\n",
        "  \n",
        "  return model\n",
        " \n",
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(generator, discriminator):\n",
        "\t\n",
        "  # make weights in the discriminator not trainable\n",
        "  for layer in discriminator.layers:\n",
        "    if not isinstance(layer, BatchNormalization):\n",
        "      layer.trainable = False\n",
        "\n",
        "  gen_image, gen_label = generator.input\n",
        "\n",
        "  gen_output = generator.output\n",
        "  gan_output = discriminator(gen_output)\n",
        "\n",
        "  model = Model([gen_image, gen_label], gan_output)\n",
        "  \n",
        "\t# compile model\n",
        "  opt = RMSprop(lr=0.00005)\n",
        "  model.compile(loss=[wasserstein_loss, 'binary_crossentropy'], optimizer=opt, metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hudjm-fW2KhC"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMsl4IZg2UI1"
      },
      "source": [
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, inception_model, dataset, latent_dim, n_epochs=20, n_batch=64):\n",
        "    bat_per_epo = int(202599 / n_batch)\n",
        "    # manually enumerate epochs\n",
        "    for i in range(n_epochs):\n",
        "      start = time.time()\n",
        "\n",
        "      # enumerate batches over the training set\n",
        "      for j in range(bat_per_epo):\n",
        "\n",
        "        # train discriminator 3 times as the generator\n",
        "        for k in range(3):\n",
        "          # get randomly selected 'real' samples\n",
        "          [X_real, labels_real], y_real = generate_real_samples(dataset)\n",
        "          current_batch_size = X_real.shape[0]\n",
        "          \n",
        "          labels_real = np.array(labels_real).reshape(current_batch_size, 15)\n",
        "          \n",
        "          # update discriminator model weights\n",
        "          d1_history = d_model.train_on_batch(X_real, [y_real, labels_real])\n",
        "                    \n",
        "          # generate 'fake' examples\n",
        "          [X_fake, labels_fake], y_fake = generate_fake_samples(\n",
        "              g_model, latent_dim, current_batch_size)\n",
        "          \n",
        "          # update discriminator model weights\n",
        "          d2_history = d_model.train_on_batch(X_fake, [y_fake, labels_fake])\n",
        "          \n",
        "        # prepare points in latent space as input for the generator\n",
        "        X_gan, label_gan = generate_latent_points(latent_dim, current_batch_size)\n",
        "        # create inverted labels for the fake samples\n",
        "        y_gan = -np.ones((current_batch_size, 1))\n",
        "        \n",
        "        # update the generator via the discriminator's error\n",
        "        g_history = gan_model.train_on_batch([X_gan, label_gan], [y_gan, label_gan])\n",
        "        # summarize loss on this batch\n",
        "        if ((j + 1) % 200 == 0):\n",
        "          print('Epoch %d\\tbatch %d/%d\\td1=%.3f\\td2=%.3f\\tg=%.3f' %\n",
        "              (i+1, j+1, bat_per_epo, d1_history[0], d2_history[0], g_history[0]))\n",
        "\n",
        "        if ((j + 1) % 1000 == 0):\n",
        "            random_idx = np.random.randint(0, 202599)\n",
        "            custom_label = attributes['attributes'][random_idx]\n",
        "            [fake, label_fake], _ = generate_fake_samples(generator, latent_dim, 64, custom_label=custom_label)\n",
        "            \n",
        "            print(decode_label(list(custom_label)))\n",
        "            save_generated_images(fake, i, j, n_batch)\n",
        "      \n",
        "      end = time.time()\n",
        "      print(\"Elapsed time: {} minutes and {:.2f} seconds\".format(int((end-start)//60), (end-start)%60))\n",
        "    \n",
        "      # save the models\n",
        "      g_model.save(g_model_path)\n",
        "      d_model.save(d_model_path)\n",
        "      g_model.save(g_model_path_drive)\n",
        "      d_model.save(d_model_path_drive)\n",
        " \n",
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "\n",
        "# create the discriminator\n",
        "#if os.path.exists('d_model_path'):\n",
        "#  print(\"Loaded discriminator from drive\")\n",
        "#  discriminator = load_model('/content/Discriminators/discriminator.h5', custom_objects={​​​​'ClipConstraint': ClipConstraint, 'wasserstein_loss': wasserstein_loss}​​​​)\n",
        "#else:\n",
        "discriminator = define_discriminator()\n",
        "\n",
        "\n",
        "# create the generator\n",
        "#if os.path.exists('g_model_path'):\n",
        "#  print(\"Loaded generator from drive\")\n",
        "#  generator = load_model('/content/Generators/generator.h5', custom_objects={​​​​'ClipConstraint': ClipConstraint}​​​​)\n",
        "#else:\n",
        "generator = define_generator(latent_dim)\n",
        "\n",
        "# create the gan\n",
        "gan_model = define_gan(generator, discriminator)\n",
        "\n",
        "# load image data\n",
        "dataset = load_dataset(cropped_path, attributes, 64, (64,64,3))\n",
        "\n",
        "# prepare the inception model\n",
        "inception = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n",
        "\n",
        "# train model\n",
        "train(generator, discriminator, gan_model, inception, dataset, latent_dim, n_epochs=15, n_batch=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXRaruOX4Tr3"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbsiiAG54XdZ"
      },
      "source": [
        "## FID value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUHYb13iU4-w"
      },
      "source": [
        "drive = False\n",
        "\n",
        "if drive:\n",
        "  generator = load_model('/content/Generators/generator.h5')\n",
        "else:\n",
        "  generator = load_model('/content/drive/MyDrive/Generators/generator.h5')\n",
        "\n",
        "real_for_fid = []\n",
        "fake_for_fid = []\n",
        "\n",
        "for i in range(10000//64 + 10000%64):\n",
        "  [real, label_real], _ = generate_real_samples(dataset)\n",
        "  [fake, label_fake], _ = generate_fake_samples(generator, latent_dim, 64)\n",
        "  real_for_fid.append(real)\n",
        "  fake_for_fid.append(fake)\n",
        "\n",
        "real_images = np.array(real_for_fid).reshape(len(real_for_fid)*64 , 64, 64, 3)\n",
        "fake_images = np.array(fake_for_fid).reshape(len(fake_for_fid)*64 , 64, 64, 3)\n",
        "fid = calculate_fid(inception, real, fake)\n",
        "print(\"Fid score calculated on {} real images and {} fake images: {:.2f}\".format(real_images.shape[0], fake_images.shape[0], fid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZxcOjtqXXbv"
      },
      "source": [
        "## Custom label generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cML03IeHOfh9"
      },
      "source": [
        ".      |           |    |           |    |           |    |         .\r\n",
        "-------|-----------|----|-----------|----|-----------|----|----------\r\n",
        "5_o_Clock_Shadow | Blurry | Male | Sideburns\r\n",
        "Arched_Eyebrows | Brown_Hair | Mouth_Slightly_Open | Smiling\r\n",
        "Attractive | Bushy_Eyebrows | Mustache | Straight_Hair\r\n",
        "Bags_Under_Eyes | Chubby | Narrow_Eyes | Wavy_Hair\r\n",
        "Bald | Double_Chin | No_Beard | Wearing_Earrings\r\n",
        "Bangs | Eyeglasses | Oval_Face | Wearing_Hat\r\n",
        "Big_Lips | Goatee | Pale_Skin | Wearing_Lipstick\r\n",
        "Big_Nose | Gray_Hair | Pointy_Nose | Wearing_Necklace\r\n",
        "Black_Hair | Heavy_Makeup | Receding_Hairline | Wearing_Necktie\r\n",
        "Blond_Hair | High_Cheekbones | Rosy_Cheeks | Young"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R15EdrJiXW31"
      },
      "source": [
        "for i in range(10):\r\n",
        "  custom_label = attributes['attributes'][np.random.randint(0, 202599)]\r\n",
        "  print(decode_label(custom_label))\r\n",
        "  [real, label_real], _ = generate_real_samples(dataset)\r\n",
        "  [fake, label_fake], _ = generate_fake_samples(generator, latent_dim, 64, custom_label=custom_label)\r\n",
        "  save_generated_images(fake, 0, 0, 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA3IisHC2VfO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}